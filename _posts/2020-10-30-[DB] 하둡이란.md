---
subtitle: db hadoop
date: 2020-10-30 23:30:28 -0400
categories: DB 
tags: [DB, HADOOP]
---

# 서론
빅데이터 시대에 접어들면서 여러 AI 관련 용어와 빅데이터 관련 용어나 기술들을 접하는 일이 많아졌다. 그 중 하나인 `하둡`에 대해서 그 자세한 특징들에 대해 알아보고자 한다.


<br>

## 하둡이란?
빅데이터분석이 쉬워진것은 하둡(Hadoop)이 개발되면서 부터이다.
하둡은 대용량 데이터를 적은비용으로 더 빠르게 분석할 수 있는 소프트웨어이며, 빅데이터 처리와 분석을 위한 플랫폼 중 사실상 표준으로 자리잡고 있다.
이러한 하둡을 사용하고 있는 큰 서비스의 예로는
- 페이스북의 자동 이미지검색
- 금융거래 내역 분석을 통한 사기방지
- 검색 패턴을 통한 광고타켓 및 마케팅 

등의 다양한 분야에서 사용되고 있다.
하둡 기술의 원리는 다음과 같다.

> 하둡은 여러개의 컴퓨터를 하나로 묶어 대용량데이터를 처리하는 기술로 , 수천대의 분산된 x86장비에 대용량 파일을 저장할 수 있는 기능을 제공하는 분산파일 시스템과, 저장된 파일을 분산된 서버의 CPU와 메모리 자원을 이용하여 빠르게 분석하는 맵리듀스 플랫폼으로 구성되어 있다.

위의 내용을 짐작하여 볼때 큰 특징은 분산 파일 시스템이라는 것이다. 요새 일반적인 스케일의 서비스들은 모두 DB를 사용하지만 하둡은 수천대의 서버 장비에 파일시스템 방식으로 저장하는 방식인 셈이다.

페이스북은 대용량의 사진 데이터를 약 2천여개의 서버가 데이터처리를 하여, 사용자가 이미지를 업로드하거나 검색할수 있게 해 준다.

<br><br>

## 하둡 에코 시스템

일반적으로 하둡파일시스템(HDFS)과 맵리듀스(MapReduce)프레임워크로 시작되었으나, 여러 데이터저장, 실행엔진, 프로그래밍 및 데이터처리 같은 하둡 생태계 전반을 포함하는 의미로 확장 발전 되었다.
하둡 소프트웨어와 더불어 하나의 큰 생태계를 이루며 분산저장 시스템을 만드는 영역은 크게 5가지 파트가 있다.

1. 분산 코디네이터
1. 분산 리소스관리
1. 데이터 저장
1. 데이터 수집
1. 데이터 처리

<br>

### 분산 코디네이터

 - Zookeeper 
분산환경에서 서버간의 상호 조정이 필요한 다양한 서비스를 제공하는 시스템이다. 
분산 동기화를 제공하고 그룹 서비스를 제공하는 중앙 집중식 서비스로 알맞은 분산처리 및 분산 환경을 구성하는 서버 설정을 통합적으로 관리 한다.

### 분산 리소스 관리
- YARN 
작업 스케줄링 및 클러스터 리소스 관리를 위한 프레임워크로 맵리듀스, 하이브, 임팔라, 스파크 등 다양한 애플리케이션들은 얀에서 작업을 실행한다.
- Mesos (클라우드환경에대한 리소스관리)
Mesos는 Linux커널과 동일한 원칙을 사용하며 컴퓨터에  API(예:Hadoop,Spark,Kafka,Elasticsearch)를 제공한다
페이스북, 트위터, 이베이등 다양한 기업들이 메소스 클러스터 자원을 관리하고 있다.

### 데이터 저장 

- HBase (분산 데이터베이스)
HBase는 구글 Bigtable을 기반으로 개발된 비관계형 데이터베이스이며, Hadoop및 HDFS위에 Bigtable과 같은 기능을 제공하게 된다. 네이버 라인 메신져에 HBase를 적용한 시스템 아키텍쳐를 발표 하기도 했다.
- HDFS (분산파일데이터저장)
애플리케이션 데이터에 대한 높은 처리량의 액세스를 제공하는 분산 파일 시스템
- Kudu (컬럼기반 스토리지)
컬럼기반 스토리지로 하둡 에코 시스템에 새로 추가되어 급변하는 데이터에 대한 빠른 분석을 위해 설계되었다.
클라우데라에서 시작된 프로젝트로, 15년말 아파치 인큐베이션 프로젝트로 선정 되었다.

### 데이터 수집
- Chukwa 
Chukwa는 분산 환경에서 생성되는 데이터를 안정적으로 HDFS에 저장하는 플랫폼이다.
대규모 분산 시스템을 모니터링 하기 위한 시스템으로, HDFS및 MapReduce 에 구축되어 수집된 데이터를 최대한 활용하기 위한 모니터링 및 유연한 툴킷을 포함한다.
- Flume
Flume은 많은 양의 데이터를 수집, 집계 및 이동하기위한 분산형 서비스이다.
- Scribe
페이스북에서 개발한 데이터 수집 플랫폼이며, Chukwa와 다르게 데이터를 중앙서버로 전송하는 방식이며, 최종 데이터는 다양한 저장소로 활용할 수 있다.
- Kafka
카프카는 데이터 스트림을 실시간으로 관리하기 위한 분산 시스템으로, 대용량 이벤트 처리를 위해 개발 되었다.

### 데이터 처리

- Pig
하둡에 저장된 데이터를 맵리듀스 프로그램을 만들지 않고 SQL과 유사한 스크립트를 이용해 데이터를 처리, 맵리듀스 API를 매우 단순화한 형태로 설계 되었다 .
- Mahout
분석 기계학습에 필요한 알고리즘을 구축하기위한 오픈소스 프레임워크이며, 클러스터링, 필터링, 마이닝, 회귀분석 등 중요 알고리즘을 지원해 준다 .
- Spark
대규모 데이터 처리를 위한 빠른 속도로 실행시켜 주는 엔진이다.
스파크는 병렬 애플리케이션을 쉽게 만들수 있는 80개 이상의 고급 연산자를 제공하며 파이썬,R등에서 대화형으로 사용할 수 있다.
- Impale
임팔라는 하둡기반 분산 엔진으로, 맵리듀스를 사용하지 않고 C++로 개발한 인메모리 엔진을 사용해 빠른 성능을 보여준다.
- Hive
하둡기반 데이터 솔루션으로, 페이스북에서 개발한 오픈소스로 자바를 몰라도 데이터분석을 할수 있게 도와 준다.
SQL과 유사한 HiveQL이라는 언어를 제공하여 쉽게 데이터 분석을 할 수 있게 도와 준다.
- MapReduce 
MapReduce 는 대용량 데이터를 분산 처리 하기위한 프로그램으로 정렬된 데이터를 분산처리Map하고 이를 다시 합치는 Reduce 과정을 거친다.하둡에서 대용량 데이터 처리를 위한 기술중 큰 인기를 누리고 있다.


분산 코디네이터
 - Zookeeper 
분산환경에서 서버간의 상호 조정이 필요한 다양한 서비스를 제공하는 시스템이다. 
분산 동기화를 제공하고 그룹 서비스를 제공하는 중앙 집중식 서비스로 알맞은 분산처리 및 분산 환경을 구성하는 서버 설정을 통합적으로 관리 한다.
분산 리소스관리
- YARN 
작업 스케줄링 및 클러스터 리소스 관리를 위한 프레임워크로 맵리듀스, 하이브, 임팔라, 스파크 등 다양한 애플리케이션들은 얀에서 작업을 실행한다.
- Mesos (클라우드환경에대한 리소스관리)
Mesos는 Linux커널과 동일한 원칙을 사용하며 컴퓨터에  API(예:Hadoop,Spark,Kafka,Elasticsearch)를 제공한다
페이스북, 트위터, 이베이등 다양한 기업들이 메소스 클러스터 자원을 관리하고 있다.
데이터저장 
- HBase (분산 데이터베이스)
HBase는 구글 Bigtable을 기반으로 개발된 비관계형 데이터베이스이며, Hadoop및 HDFS위에 Bigtable과 같은 기능을 제공하게 된다. 네이버 라인 메신져에 HBase를 적용한 시스템 아키텍쳐를 발표 하기도 했다.
- HDFS (분산파일데이터저장)
애플리케이션 데이터에 대한 높은 처리량의 액세스를 제공하는 분산 파일 시스템
- Kudu (컬럼기반 스토리지)
컬럼기반 스토리지로 하둡 에코 시스템에 새로 추가되어 급변하는 데이터에 대한 빠른 분석을 위해 설계되었다.
클라우데라에서 시작된 프로젝트로, 15년말 아파치 인큐베이션 프로젝트로 선정 되었다.
데이터수집
- Chukwa 
Chukwa는 분산 환경에서 생성되는 데이터를 안정적으로 HDFS에 저장하는 플랫폼이다.
대규모 분산 시스템을 모니터링 하기 위한 시스템으로, HDFS및 MapReduce 에 구축되어 수집된 데이터를 최대한 활용하기 위한 모니터링 및 유연한 툴킷을 포함한다.
- Flume
Flume은 많은 양의 데이터를 수집, 집계 및 이동하기위한 분산형 서비스이다.
- Scribe
페이스북에서 개발한 데이터 수집 플랫폼이며, Chukwa와 다르게 데이터를 중앙서버로 전송하는 방식이며, 최종 데이터는 다양한 저장소로 활용할 수 있다.
- Kafka
카프카는 데이터 스트림을 실시간으로 관리하기 위한 분산 시스템으로, 대용량 이벤트 처리를 위해 개발 되었다.
데이터처리
- Pig
하둡에 저장된 데이터를 맵리듀스 프로그램을 만들지 않고 SQL과 유사한 스크립트를 이용해 데이터를 처리, 맵리듀스 API를 매우 단순화한 형태로 설계 되었다 .
- Mahout
분석 기계학습에 필요한 알고리즘을 구축하기위한 오픈소스 프레임워크이며, 클러스터링, 필터링, 마이닝, 회귀분석 등 중요 알고리즘을 지원해 준다 .
- Spark
대규모 데이터 처리를 위한 빠른 속도로 실행시켜 주는 엔진이다.
스파크는 병렬 애플리케이션을 쉽게 만들수 있는 80개 이상의 고급 연산자를 제공하며 파이썬,R등에서 대화형으로 사용할 수 있다.
- Impale
임팔라는 하둡기반 분산 엔진으로, 맵리듀스를 사용하지 않고 C++로 개발한 인메모리 엔진을 사용해 빠른 성능을 보여준다.
- Hive
하둡기반 데이터 솔루션으로, 페이스북에서 개발한 오픈소스로 자바를 몰라도 데이터분석을 할수 있게 도와 준다.
SQL과 유사한 HiveQL이라는 언어를 제공하여 쉽게 데이터 분석을 할 수 있게 도와 준다.
- MapReduce 
MapReduce 는 대용량 데이터를 분산 처리 하기위한 프로그램으로 정렬된 데이터를 분산처리Map하고 이를 다시 합치는 Reduce 과정을 거친다.하둡에서 대용량 데이터 처리를 위한 기술중 큰 인기를 누리고 있다.


<br><br>

**다음 포스팅을 통해 실제 하둡에 대한 자세한 실습을 해보도록 한다.**
